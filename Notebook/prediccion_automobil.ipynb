{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Carga y Exploración de Datos:\n",
    "\n",
    "Cargar el dataset y revisar la estructura básica.\n",
    "Descripción de las variables y su distribución.\n",
    "Detección y tratamiento de valores nulos.\n",
    "Identificación y tratamiento de outliers.\n",
    "Análisis de correlación entre variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "df = pd.read_csv(\"../Data/Automobile_data.csv\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(12).T "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info() \n",
    "df.describe() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hay algunos datos que figuran como object en vez de como corresponden. Esto es porque no aparecen como NaN y aparecen como ?\n",
    "Se prosede a arregrar remplazando por nan y luego para identificar valores nulos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.replace('?', np.nan, inplace = True) \n",
    "print(df.isnull().sum()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Luego de verificar el dataset se considera a estas columnas como numericas que estan como object\n",
    "df['normalized-losses'] = pd.to_numeric(df['normalized-losses'], errors = 'coerce')\n",
    "df['bore'] = pd.to_numeric(df['bore'], errors='coerce')\n",
    "df['stroke'] = pd.to_numeric(df['stroke'], errors='coerce')\n",
    "\n",
    "#normalized-losses lo completaré con el promedio\n",
    "df['normalized-losses'] = df['normalized-losses'].fillna(df['normalized-losses'].mean())\n",
    "#numero de puertas con moda\n",
    "df['num-of-doors'] = df['num-of-doors'].fillna(df['num-of-doors'].mode()[0])\n",
    "#bore y stroke también hare con el promedio\n",
    "\n",
    "df['bore'] = df['bore'].fillna(df['bore'].mean())\n",
    "df['stroke'] = df['stroke'].fillna(df['stroke'].mean())\n",
    "#Horsepower, peak rpm y price considero que es muy importante entonces no lo promedio, mejor lo elimino\n",
    "df.dropna(subset = ['horsepower', 'peak-rpm', 'price'], inplace = True)\n",
    "#Ahora verifico\n",
    "print(df.isnull().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Modifiquemos los tipos de datos de las columnas que sean necesarias\n",
    "df['normalized-losses'] = df['normalized-losses'].astype(int)\n",
    "df['num-of-doors'] = df['num-of-doors'].astype('category')\n",
    "df['horsepower'] = df['horsepower'].astype(int)\n",
    "df['peak-rpm'] = df['peak-rpm'].astype(int)\n",
    "print(df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ahora trataremos los outliers\n",
    "sns.boxplot(data = df[['horsepower', 'city-mpg', 'highway-mpg']])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Considero que estos valores son posibles así que no los elimino\n",
    "#Ahora haremos un análisis de correlación entre las variables\n",
    "df_numeric = df.select_dtypes(include = ['int64', 'float64'])\n",
    "corr_matrix = df_numeric.corr(method = 'pearson') #si no pongo el método el usará pearson por defecto\n",
    "plt.figure(figsize = (12, 10))\n",
    "sns.heatmap(corr_matrix, annot = True, cmap = 'coolwarm')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " 2. Preprocesamiento:\n",
    "\n",
    "Selección de características importantes.\n",
    "Transformación de variables categóricas.\n",
    "División del conjunto de datos en entrenamiento y prueba.\n",
    "Escalado de características."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {} #Esto es para almacenar los resultados\n",
    "#Ahora seleccionaremos las variables que vamos a usar\n",
    "X = df.drop(['price'], axis = 1) #Con esto selecciono todo menos price\n",
    "y = df['price'].astype(float)\n",
    "\n",
    "#Dividimos el conjunto de datos en entrenamiento y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42)\n",
    "\n",
    "#Debemos dividir las columnas categóricas y numéricas\n",
    "categorical_features = X.select_dtypes(include = ['object']).columns\n",
    "numerical_features = X.select_dtypes(include=['number']).columns\n",
    "\n",
    "#Creamos el preprocesador usando ColumnTransformer\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers = [\n",
    "        ('num', StandardScaler(), numerical_features),\n",
    "        ('cat', OneHotEncoder(handle_unknown = 'ignore'), categorical_features)\n",
    "    ]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Regresión Lineal:\n",
    "\n",
    "Entrenamiento del modelo.\n",
    "Evaluación del rendimiento (MSE y R²).\n",
    " \n",
    "\n",
    "4. K-Nearest Neighbors (KNN):\n",
    "\n",
    "Entrenamiento del modelo.\n",
    "Evaluación del rendimiento (MSE y R²).\n",
    "\n",
    "5. Árbol de Decisión:\n",
    "\n",
    "Entrenamiento del modelo.\n",
    "Evaluación del rendimiento (MSE y R²).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creamos el pipeline para la regresión lineal\n",
    "pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('regressor', LinearRegression())\n",
    "])\n",
    "\n",
    "#Ajustamos el modelo a los datos de entrenamiento\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "#Realizamos las predicciones\n",
    "y_pred = pipeline.predict(X_test)\n",
    "#Evaluamos el rendimiento (MSE y R2)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "results['Regresión lineal'] = {'MSE': mse, 'R2': r2}\n",
    "print(f'Regresión lineal - MSE: {mse:.2f}, R2: {r2:.2f}')\n",
    "\n",
    "#Ahora vamos con el K-Nearest Neighbors\n",
    "#Creamos el pipeline para el KNN\n",
    "pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('regressor', KNeighborsRegressor(n_neighbors = 5))\n",
    "])\n",
    "\n",
    "#Entrenamos el modelo\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "#Realizamos las predicciones\n",
    "y_pred = pipeline.predict(X_test)\n",
    "\n",
    "#Evaluamos el rendimiento (MSE y R2)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "results['KNN'] = {'MSE': mse, 'R2': r2}\n",
    "print(f'KNN - MSE: {mse:.2f}, R2: {r2:.2f}')\n",
    "\n",
    "#Ahora vamos el el árbol de decisión\n",
    "pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('regressor', DecisionTreeRegressor(random_state = 0))\n",
    "])\n",
    "\n",
    "#Entrenamos el modelo\n",
    "pipeline.fit(X_train, y_train)\n",
    "y_pred = pipeline.predict(X_test)\n",
    "\n",
    "#Evaluamos el rendimiento (MSE y R2)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "results['Arbol de decisión'] = {'MSE': mse, 'R2': r2}\n",
    "print(f'Arbol de decisión: - MSE: {mse:.2f}, R2: {r2:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Comparación de Modelos:\n",
    "\n",
    "Comparar los resultados de los tres modelos en términos de MSE y R².\n",
    "Discusión sobre las diferencias en el rendimiento de los modelos.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ahora comparamos los resultados de los tres modelos\n",
    "#podemos hacer un dataframe con los resultados\n",
    "results_df = pd.DataFrame(results).T\n",
    "print(results_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. Interpretación de Resultados:\n",
    "\n",
    "Analizar cuál de los modelos es más adecuado para el problema de predicción de precios de autos.\n",
    "Discutir posibles mejoras y próximos pasos, como el ajuste de hiperparámetros o el uso de técnicas avanzadas.\n",
    "\n",
    "# Regresión Lineal\n",
    "MSE extremadamente alto: Esto indica que el modelo no está prediciendo correctamente. Es probable que la relación entre las variables no sea lineal, lo que causa un desempeño tan deficiente.\n",
    "R² negativo y muy bajo: Un R² negativo significa que el modelo es peor que simplemente predecir el promedio de y. Esto confirma que la Regresión Lineal no es adecuada para este conjunto de datos.\n",
    "Conclusión: Este modelo no es útil para este problema, ya que no captura adecuadamente la relación entre las variables.\n",
    "\n",
    "# KNN (K-Nearest Neighbors)\n",
    "MSE moderadamente bajo: Aunque no es el modelo más preciso, el error promedio es razonablemente bajo en comparación con la Regresión Lineal.\n",
    "R² positivo (0.6519): Indica que el modelo explica el 65.19% de la variabilidad en los datos. Esto sugiere un desempeño moderado, pero no óptimo.\n",
    "Conclusión: El modelo KNN funciona mejor que la Regresión Lineal, pero podría no ser el ideal para este problema. Ajustar el número de vecinos podría mejorar el desempeño.\n",
    "\n",
    "# Árbol de Decisión\n",
    "MSE más bajo entre los tres modelos: este modelo tiene el menor error promedio, lo que indica que predice más precisamente.\n",
    "R² más alto: El modelo explica el 88.21% de la variabilidad en los datos, lo que sugiere que captura bien las relaciones no lineales en el conjunto.\n",
    "Conclusión: El Árbol de Decisión es el modelo más adecuado entre los tres, ya que tiene el menor error y explica la mayor parte de la variabilidad en los datos.\n",
    "\n",
    "Conclusión general:\n",
    "El Árbol de Decisión es el modelo más efectivo para este problema, ya que:\n",
    "\n",
    "Tiene el menor MSE, indicando predicciones más precisas.\n",
    "Posee el mayor R² (0.8821), lo que sugiere que es capaz de capturar mejor las relaciones complejas en los datos.\n",
    "\n",
    "Sin embargo, sería prudente considerar lo siguiente:\n",
    "\n",
    "Validación cruzada: Para confirmar que el modelo generaliza bien y evitar el riesgo de sobreajuste.\n",
    "Hiperparámetros: Explorar ajustes en la profundidad máxima del árbol (max_depth) o en los criterios de división para afinar el modelo.\n",
    "Otros modelos: Puedes probar técnicas avanzadas como Random Forest o Gradient Boosting para mejorar aún más el rendimiento."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
